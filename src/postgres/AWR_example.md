## PostgreSQL AWR in action

**Sample prompts**:
- Generate a performance report using pg-awr
- Find top 5 SQL statement by CPU and IO usage, suggest optimization if any
- Model Claude Sonnet 4.5 (Thinking)

Here is an example of a performance report generated by the `pg-awr` tool for a production Moodle database, highlighting critical performance issues and optimization opportunities:

### **Database Configuration**
- **Database**: moodle
- **Active Connections**: 2
- **Transactions Committed**: 13,281
- **Transactions Rolled Back**: 11

### **Performance Metrics**

#### **Buffer Cache** ðŸ”´ **Critical Issue**
- **Cache Hit Ratio**: 39.32% âš ï¸ (Very Low - significant disk I/O)
- **Blocks Read**: 5.16M (from disk)
- **Blocks Hit**: 3.34M (from cache)
- **Target**: >95% for optimal performance

#### **Temporary Files** ðŸ”´ **Critical Issue**
- **Temp Files**: 346 âš ï¸ (Very High)
- **Temp Bytes**: 3.8 GB âš ï¸ (Indicates insufficient work_mem)
- **Deadlocks**: 0 âœ…

#### **Data Activity**
- **Tuples Returned**: 158.8M
- **Tuples Fetched**: 406,157
- **Tuples Inserted**: 32.8M
- **Tuples Updated**: 5,545
- **Tuples Deleted**: 14

### **Top 5 Tables by CPU Usage (Sequential Scans)**

#### **1. mdl_logstore_standard_log** ðŸ”´ **Critical**
- **Sequential Scans**: 10 scans
- **Rows Read via Seq Scan**: 87.4M rows
- **Average Rows per Scan**: 8.7M rows
- **Index Scans**: Only 6 (very low)
- **Issue**: Massive full table scans with minimal index usage

**Optimization**:
```sql
-- Time-based queries
CREATE INDEX CONCURRENTLY idx_logstore_timecreated 
ON mdl_logstore_standard_log(timecreated) 
WHERE timecreated IS NOT NULL;

-- User-based queries
CREATE INDEX CONCURRENTLY idx_logstore_userid_time 
ON mdl_logstore_standard_log(userid, timecreated);

-- Context-based queries
CREATE INDEX CONCURRENTLY idx_logstore_contextid 
ON mdl_logstore_standard_log(contextid) 
WHERE contextid IS NOT NULL;
```

#### **2. mdl_grade_grades_history** ðŸ”´ **Critical**
- **Sequential Scans**: 20 scans
- **Rows Read**: 15.7M rows
- **Average per Scan**: 786K rows
- **Index Scans**: 0 (no indexes being used)

**Optimization**:
```sql
CREATE INDEX CONCURRENTLY idx_grades_hist_userid_time 
ON mdl_grade_grades_history(userid, timemodified);

CREATE INDEX CONCURRENTLY idx_grades_hist_itemid 
ON mdl_grade_grades_history(itemid);
```

#### **3. mdl_question_attempt_steps** âš ï¸ **High**
- **Sequential Scans**: 8 scans
- **Rows Read**: 6.3M rows
- **Index Scans**: 0

**Optimization**:
```sql
CREATE INDEX CONCURRENTLY idx_attempt_steps_questionattemptid 
ON mdl_question_attempt_steps(questionattemptid);

CREATE INDEX CONCURRENTLY idx_attempt_steps_sequencenumber 
ON mdl_question_attempt_steps(questionattemptid, sequencenumber);
```

#### **4. mdl_question_attempt_step_data** âš ï¸ **High**
- **Sequential Scans**: 4 scans
- **Rows Read**: 5.0M rows
- **Average per Scan**: 1.24M rows

**Optimization**:
```sql
CREATE INDEX CONCURRENTLY idx_attempt_step_data_attemptstepid 
ON mdl_question_attempt_step_data(attemptstepid);
```

#### **5. mdl_analytics_predict_samples** âš ï¸ **High**
- **Sequential Scans**: 6 scans
- **Rows Read**: 4.7M rows

**Optimization**:
```sql
CREATE INDEX CONCURRENTLY idx_analytics_samples_modelid_time 
ON mdl_analytics_predict_samples(modelid, timecreated, rangeindex);
```

### **Unused Indexes** ðŸŸ¡ **Medium Priority**

Found **10 unused indexes** consuming ~2.5 GB of disk space:
- `mdl_logsstanlog_useconconcr_ix` (985 MB) - 0 scans
- `mdl_logsstanlog_tim_ix` (375 MB) - 0 scans
- `mdl_logsstanlog_con_ix` (375 MB) - 0 scans
- `mdl_logsstanlog_id_pk` (375 MB) - 0 scans
- And 6 more...

**Action**: Review and drop unused indexes to improve write performance and save disk space.

### **Recommendations**

#### ðŸ”´ **Critical Priority**

1. **Increase Buffer Cache** (shared_buffers)
   - Current cache hit ratio: 39.32% (should be >95%)
   - **Action**: Increase `shared_buffers` to at least 25% of system RAM
   - Example: If you have 16GB RAM, set `shared_buffers = 4GB`

2. **Increase Work Memory** (work_mem)
   - 346 temporary files created, consuming 3.8 GB
   - **Action**: Increase `work_mem` to at least 64MB
   - This will reduce disk I/O for sorts and joins

3. **Add Missing Indexes**
   - Tables are experiencing massive sequential scans (87M+ rows)
   - **Action**: Create indexes as shown in optimization suggestions above

#### ðŸŸ¡ **Medium Priority**

4. **Remove Unused Indexes**
   - 10 indexes consuming ~2.5 GB with 0 scans
   - **Action**: Evaluate and drop unused indexes

5. **Enable pg_stat_statements**
   - Get query-level statistics for better optimization
   ```sql
   -- Add to postgresql.conf
   shared_preload_libraries = 'pg_stat_statements'
   pg_stat_statements.track = all
   ```

### **Configuration Recommendations**

Add to `postgresql.conf`:
```ini
shared_buffers = 4GB          # Increase from current (adjust based on RAM)
work_mem = 64MB               # Increase from current
effective_cache_size = 12GB   # Set to ~75% of system RAM
maintenance_work_mem = 512MB  # For faster index creation/vacuum
```

**Estimated Impact**: These optimizations should:
- Improve cache hit ratio from 39% to >90%
- Reduce sequential scans by 80%+
- Eliminate excessive temporary file usage
- Free up 2.5 GB of disk space
